{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll be implementing given standard functions for our Decision Tree Classifier:\n",
    "### 1.Entropy Function \n",
    "### 2.Information Gain Function\n",
    "### 3.Split Info function\n",
    "### 4.Best feature and Maximum Gain Function\n",
    "### 5.Decision Tree Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    #entropy is -(summation of p(ith)logp(ith)) for i classes\n",
    "    #note: We have assumed target/y has 1 column only.\n",
    "    \n",
    "    total_elements = len(y)  \n",
    "    entropy_value = 0  \n",
    "    \n",
    "    labels_in_y= np.unique(y)\n",
    "    \n",
    "    for l in labels_in_y:  \n",
    "        number_of_ith_class = len(y[y== l])   \n",
    "        prob_of_ith_class = number_of_ith_class/total_elements     \n",
    "        entropy_value += prob_of_ith_class * math.log(prob_of_ith_class, 2)  \n",
    "        \n",
    "    entropy_value = -entropy_value\n",
    "    \n",
    "    return entropy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(x, y, feature) :\n",
    "    \n",
    "    #information gain is= entropy before splitting - entropy after splitting\n",
    "    #entropy after splitting is summation of weighted entropies\n",
    "    \n",
    "    entropy_before_split= entropy(y)  \n",
    "    total_elements = len(y)   \n",
    "    entropy_after_split = 0   \n",
    "    \n",
    "    #x[feature] gives data points /column for the selected feature\n",
    "    #unique_values gives the total no of labels available in this feature \n",
    "    unique_values = set(x[feature])  \n",
    "    \n",
    "    #our splitting is that for given feature, no of splits is = no of unique values in this feature\n",
    "    for i in unique_values:\n",
    "        child = y[(x[feature] == i)]\n",
    "        i_entropy = entropy(child)\n",
    "        \n",
    "        #finding summation of weighted entropies\n",
    "        entropy_after_split += (i_entropy * len(child)) / total_elements\n",
    "        \n",
    "    info_gain = entropy_before_split - entropy_after_split  \n",
    "    \n",
    "    return info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_information(x, y, feature) :\n",
    "    #split info is negative summation of weighted logarithms of weighted avgs\n",
    "    total_elements= len(y)\n",
    "    SI= 0\n",
    "    unique_values = set(x[feature])\n",
    "    \n",
    "    for i in unique_values :  \n",
    "        \n",
    "        child = y[x[feature] == i] \n",
    "        \n",
    "        weighted_avg_for_this_child= len(child) / total_elements\n",
    "        w=weighted_avg_for_this_child\n",
    "        \n",
    "        SI +=  w* math.log(w, 2) \n",
    "        \n",
    "    return -1 * SI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split_possible(x,y,features):\n",
    "    #we need to find best feature and max gain in order to find best split possible\n",
    "    #max gain means max information gain found\n",
    "    #initializing best feature and max gain\n",
    "    best_feature = '' \n",
    "    max_gain_ratio = -1  \n",
    "    \n",
    "    #we need to select feature with max gain ratio\n",
    "    #gain ratio is =info gain/split info\n",
    "    \n",
    "    for f in features :\n",
    "        \n",
    "        \n",
    "        split_info = split_information(x, y, f)\n",
    "        info_gain = information_gain(x, y, f)\n",
    "        \n",
    "        if split_info != 0 :\n",
    "            gain_ratio = info_gain / split_info\n",
    "            \n",
    "        else :\n",
    "            #this would be the case when split info is 0\n",
    "            gain_ratio = -1\n",
    "        \n",
    "        \n",
    "        ####\n",
    "        if gain_ratio > max_gain_ratio :\n",
    "            best_feature = f\n",
    "            max_gain_ratio = gain_ratio\n",
    "        ####    \n",
    "    \n",
    "    return best_feature, max_gain_ratio\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT(x,y,features,level):\n",
    "    \n",
    "    #classes will be the classes available to use for current y\n",
    "    classes=np.unique(y)   \n",
    "    #now we will code our base cases\n",
    "    \n",
    "    ######\n",
    "    # base case 1, we have leaf node \n",
    "    if (len(classes) == 1): \n",
    "            \n",
    "        print(\"Level \",level)   \n",
    "        c = list(classes)[0]    \n",
    "        \n",
    "        print(\"Count of \",c,\" = \",len(y))   \n",
    "        #leaf node has zero entropy\n",
    "        print(\"Current Entropy is = 0.0\")                 \n",
    "        print(\"Reached leaf Node\")                          \n",
    "        print(\"Output Class Name =\", c)\n",
    "        print()\n",
    "        return\n",
    "    ######\n",
    "    \n",
    "    \n",
    "    \n",
    "    ######\n",
    "    # base case 2\n",
    "    #if we have 0 features, no further splitting possible\n",
    "    elif len(features)==0:                                                            \n",
    "        print(\"Level  \",level)     \n",
    "        countOfClasses=[]\n",
    "        #printing count of all classes available to us currently\n",
    "        for currently_available_class in classes:\n",
    "            count_of_currently_avail_class = (y == currently_available_class).sum() \n",
    "            countOfClasses.append(count_of_currently_avail_class)\n",
    "            print(\"Count of \",currently_available_class,\" = \",count_of_currently_avail_class) \n",
    "            \n",
    "        entropy_current = entropy(y)\n",
    "        \n",
    "        #we will print the majority class\n",
    "        #finding index of majority class\n",
    "        i=countOfClasses.index(max(countOfClasses))\n",
    "        \n",
    "        print(\"Current Entropy is = \",entropy_current)\n",
    "        print(\"No more features left\")\n",
    "        print(\"Reached leaf Node\")\n",
    "        print(\"Output Class Name =\", classes[i])\n",
    "        print()\n",
    "        return\n",
    "    ######\n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################\n",
    "    # Working of DT \n",
    "    else:\n",
    "        \n",
    "        print(\"Level \",level)        \n",
    "        \n",
    "        #we'll find the class with maximum data pts and take it as our output class\n",
    "        max_count = 0\n",
    "        for current_class in classes:             \n",
    "            countOfCurrentClass = (y==current_class).sum()      \n",
    "            print(\"Count of \",current_class,\" = \",countOfCurrentClass)\n",
    "            \n",
    "            if countOfCurrentClass>= max_count :\n",
    "                max_count = countOfCurrentClass\n",
    "                output_class  = current_class\n",
    "        \n",
    "        \n",
    "        print(\"Current Entropy is =\",entropy(y))\n",
    "        \n",
    "        best_feature,gain_ratio = best_split_possible(x,y,features)\n",
    "        print(\"Splitting on feature \",best_feature,\"with gain ratio :\",gain_ratio)\n",
    "        print(\"Output Class Name =\", output_class)\n",
    "        print()\n",
    "        \n",
    "        values_in_best_feature = set(x[best_feature]) \n",
    "        \n",
    "        for value in values_in_best_feature:\n",
    "            \n",
    "            xnew=x[(x[best_feature] == value)]\n",
    "            ynew=y[(x[best_feature] == value)]\n",
    "\n",
    "            # we'll update our feature set\n",
    "            remaining_features = features - {best_feature}\n",
    "            #recursion call with updates x,y,features and level\n",
    "            DT(xnew,ynew,remaining_features,level+1)\n",
    "        return\n",
    "    #################################################\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data)\n",
    "df.columns = [\"sl\", \"sw\", 'pl', 'pw']\n",
    "def label(val, *boundaries):\n",
    "    if (val < boundaries[0]):\n",
    "        return 'a'\n",
    "    elif (val < boundaries[1]):\n",
    "        return 'b'\n",
    "    elif (val < boundaries[2]):\n",
    "        return 'c'\n",
    "    else:\n",
    "        return 'd'\n",
    "\n",
    "#Function to convert a continuous data into labelled data\n",
    "#There are 4 lables  - a,b,c,d\n",
    "def toLabel(df, old_feature_name):\n",
    "    second = df[old_feature_name].mean()\n",
    "    minimum = df[old_feature_name].min()\n",
    "    first = (minimum + second)/2\n",
    "    maximum = df[old_feature_name].max()\n",
    "    third = (maximum + second)/2\n",
    "    return df[old_feature_name].apply(label, args= (first, second, third))\n",
    "df['sl_labeled'] = toLabel(df, 'sl')\n",
    "df['sw_labeled'] = toLabel(df, 'sw')\n",
    "df['pl_labeled'] = toLabel(df, 'pl')\n",
    "df['pw_labeled'] = toLabel(df, 'pw')\n",
    "\n",
    "df.drop(['sl', 'sw', 'pl', 'pw'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level  0\n",
      "Count of  setosa  =  50\n",
      "Count of  versicolor  =  50\n",
      "Count of  virginica  =  50\n",
      "Current Entropy is = 1.584962500721156\n",
      "Splitting on feature  pw_labeled with gain ratio : 0.699638203622209\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  1\n",
      "Count of  versicolor  =  40\n",
      "Count of  virginica  =  16\n",
      "Current Entropy is = 0.863120568566631\n",
      "Splitting on feature  pl_labeled with gain ratio : 0.4334099495621066\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  2\n",
      "Count of  versicolor  =  39\n",
      "Count of  virginica  =  8\n",
      "Current Entropy is = 0.6581912658132185\n",
      "Splitting on feature  sl_labeled with gain ratio : 0.12674503775809332\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  versicolor  =  23\n",
      "Count of  virginica  =  7\n",
      "Current Entropy is = 0.783776947484701\n",
      "Splitting on feature  sw_labeled with gain ratio : 0.07092036405148876\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  4\n",
      "Count of  versicolor  =  6\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level   4\n",
      "Count of  versicolor  =  14\n",
      "Count of  virginica  =  6\n",
      "Current Entropy is =  0.8812908992306927\n",
      "No more features left\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level   4\n",
      "Count of  versicolor  =  3\n",
      "Count of  virginica  =  1\n",
      "Current Entropy is =  0.8112781244591328\n",
      "No more features left\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  versicolor  =  2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  versicolor  =  14\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  virginica  =  1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  2\n",
      "Count of  virginica  =  8\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  2\n",
      "Count of  versicolor  =  1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  1\n",
      "Count of  virginica  =  34\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  1\n",
      "Count of  versicolor  =  10\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  1\n",
      "Count of  setosa  =  50\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = setosa\n",
      "\n",
      "Level  0\n",
      "Count of  setosa  =  50\n",
      "Count of  versicolor  =  50\n",
      "Count of  virginica  =  50\n",
      "Current Entropy is = 1.584962500721156\n",
      "Splitting on feature  pw_labeled with gain ratio : 0.699638203622209\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  1\n",
      "Count of  versicolor  =  40\n",
      "Count of  virginica  =  16\n",
      "Current Entropy is = 0.863120568566631\n",
      "Splitting on feature  pl_labeled with gain ratio : 0.4334099495621066\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  2\n",
      "Count of  versicolor  =  39\n",
      "Count of  virginica  =  8\n",
      "Current Entropy is = 0.6581912658132185\n",
      "Splitting on feature  sl_labeled with gain ratio : 0.12674503775809332\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  versicolor  =  23\n",
      "Count of  virginica  =  7\n",
      "Current Entropy is = 0.783776947484701\n",
      "Splitting on feature  sw_labeled with gain ratio : 0.07092036405148876\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  4\n",
      "Count of  versicolor  =  6\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level   4\n",
      "Count of  versicolor  =  14\n",
      "Count of  virginica  =  6\n",
      "Current Entropy is =  0.8812908992306927\n",
      "No more features left\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level   4\n",
      "Count of  versicolor  =  3\n",
      "Count of  virginica  =  1\n",
      "Current Entropy is =  0.8112781244591328\n",
      "No more features left\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  versicolor  =  2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  versicolor  =  14\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  virginica  =  1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  2\n",
      "Count of  virginica  =  8\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  2\n",
      "Count of  versicolor  =  1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  1\n",
      "Count of  virginica  =  34\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  1\n",
      "Count of  versicolor  =  10\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  1\n",
      "Count of  setosa  =  50\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = setosa\n",
      "\n",
      "Level  0\n",
      "Count of  setosa  =  50\n",
      "Count of  versicolor  =  50\n",
      "Count of  virginica  =  50\n",
      "Current Entropy is = 1.584962500721156\n",
      "Splitting on feature  pw_labeled with gain ratio : 0.699638203622209\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  1\n",
      "Count of  versicolor  =  40\n",
      "Count of  virginica  =  16\n",
      "Current Entropy is = 0.863120568566631\n",
      "Splitting on feature  pl_labeled with gain ratio : 0.4334099495621066\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  2\n",
      "Count of  versicolor  =  39\n",
      "Count of  virginica  =  8\n",
      "Current Entropy is = 0.6581912658132185\n",
      "Splitting on feature  sl_labeled with gain ratio : 0.12674503775809332\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  versicolor  =  23\n",
      "Count of  virginica  =  7\n",
      "Current Entropy is = 0.783776947484701\n",
      "Splitting on feature  sw_labeled with gain ratio : 0.07092036405148876\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  4\n",
      "Count of  versicolor  =  6\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level   4\n",
      "Count of  versicolor  =  14\n",
      "Count of  virginica  =  6\n",
      "Current Entropy is =  0.8812908992306927\n",
      "No more features left\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level   4\n",
      "Count of  versicolor  =  3\n",
      "Count of  virginica  =  1\n",
      "Current Entropy is =  0.8112781244591328\n",
      "No more features left\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  versicolor  =  2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  versicolor  =  14\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  virginica  =  1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  2\n",
      "Count of  virginica  =  8\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  2\n",
      "Count of  versicolor  =  1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  1\n",
      "Count of  virginica  =  34\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  1\n",
      "Count of  versicolor  =  10\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  1\n",
      "Count of  setosa  =  50\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = setosa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = pd.DataFrame(iris.target)\n",
    "y[y[0] == 0] = 'setosa'\n",
    "y[y[0] == 1] = 'versicolor'\n",
    "y[y[0] == 2] = 'virginica'\n",
    "features = set(df.columns)\n",
    "y=y.values\n",
    "DT(df, y, features, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
